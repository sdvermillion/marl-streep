{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.distributions import MixtureSameFamily, Categorical\n",
    "\n",
    "from distributions import CircularProjectedNormal\n",
    "\n",
    "#torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as O\n",
    "import torch.distributions as D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Ground Truth Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth loc parameters\n",
    "mu = torch.tensor(\n",
    "    [\n",
    "        [-2.19, -2.09],\n",
    "        [-0.19, 2.09]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ground truth covariance matrix\n",
    "sig11 = .9\n",
    "sig21 = .4\n",
    "rho1 = .5\n",
    "sig12 = .58\n",
    "sig22 = .4\n",
    "rho2 = -.84\n",
    "sigma = torch.tensor(\n",
    "    [\n",
    "        [[sig11**2, rho1*sig11*sig21], [rho1*sig11*sig21, sig21**2]],\n",
    "        [[sig12**2, rho2*sig12*sig22], [rho2*sig12*sig22, sig22**2]]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ground truth projected normal distribution\n",
    "mix = Categorical(torch.ones(2))\n",
    "comp = CircularProjectedNormal(mu, sigma)\n",
    "true_dist = MixtureSameFamily(mix, comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Ground Truth Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate normal sample\n",
    "X = D.MultivariateNormal(mu[0], sigma[0]).sample((500,))\n",
    "Y = D.MultivariateNormal(mu[1], sigma[1]).sample((500,))\n",
    "\n",
    "# project to circle\n",
    "U = X/X.norm(dim = 1)[:,None]\n",
    "V = Y/Y.norm(dim = 1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(X[:,0], X[:,1], '.')\n",
    "plt.plot(Y[:,0], Y[:,1], '.')\n",
    "plt.axvline(0, ls = ':')\n",
    "plt.axhline(0, ls = ':')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(U[:,0], U[:,1], '.')\n",
    "plt.plot(V[:,0], V[:,1], '.')\n",
    "plt.xlim([-1.1, 1.1])\n",
    "plt.ylim([-1.1, 1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4048\n",
    "n_components = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = torch.randn(n_components, 2)\n",
    "param_loc = nn.Parameter(loc/loc.norm(dim = 1))\n",
    "param_sig = nn.Parameter(torch.ones(n_components))\n",
    "param_gam = nn.Parameter(torch.zeros(n_components))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = O.Adam(params = (param_loc,param_sig, param_gam), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = torch.vstack((U,V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = np.zeros((num_epochs,2))\n",
    "\n",
    "theta = torch.linspace(0, 2*torch.pi, steps = 1000)\n",
    "xy = torch.stack((torch.cos(theta), torch.sin(theta))).T\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # construct covariance matrix\n",
    "    S = torch.stack((\n",
    "        torch.stack((param_sig**2 + param_gam**2, param_gam)),\n",
    "        torch.stack((param_gam, torch.tensor(n_components*[1.])))\n",
    "    )).permute(2,0,1)\n",
    "\n",
    "    # construct covariance matrix\n",
    "    #S = torch.stack((\n",
    "    #    torch.stack((torch.tensor(n_components*[1.]), torch.tensor(n_components*[0.]))),\n",
    "    #    torch.stack((torch.tensor(n_components*[0.]), torch.tensor(n_components*[1.])))\n",
    "    #)).permute(2,0,1)\n",
    "    \n",
    "    # define distribution\n",
    "    mix = Categorical(torch.ones(n_components))\n",
    "    comp = CircularProjectedNormal(param_loc, S)\n",
    "    dist = MixtureSameFamily(mix, comp)\n",
    "\n",
    "    # compute loss\n",
    "    loss = -dist.log_prob(U).mean()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lnp = true_dist.log_prob(xy)\n",
    "        lnq = dist.log_prob(xy)\n",
    "        p = lnp.exp()\n",
    "        kl = (p*lnp - p*lnq).mean()\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    hist[epoch, 0] = -loss.item()\n",
    "    hist[epoch, 1] = kl\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(hist[:,0])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(hist[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.linspace(0, 2*torch.pi, steps = 1000)\n",
    "xy = torch.stack((torch.cos(theta), torch.sin(theta))).T\n",
    "\n",
    "# true likelihood\n",
    "p = true_dist.log_prob(xy).exp()\n",
    "\n",
    "# estimated likelihood\n",
    "q = dist.log_prob(xy).exp().detach()\n",
    "\n",
    "# plot\n",
    "plt.plot(theta, p, 'k', label = 'Ground Truth Distribution')\n",
    "plt.plot(theta, q, 'r:', label = 'Estimated Distribution')\n",
    "plt.xlabel('Angle [rad]')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.polar(theta, 1 + p)\n",
    "plt.polar(theta, 1 + q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
